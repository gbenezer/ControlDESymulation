{
  "hash": "fcf9a40fd05a0aeebe3a8e378fda5663",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"ControlDESymulation Numerical Integration Framework Architecture\"\nsubtitle: \"ControlDESymulation Architecture Documentation\"\nauthor: \"Gil Benezer\"\ndate: today\nformat:\n  html:\n    toc: true\n    code-fold: show\n    code-tools: true\nexecute:\n  eval: true      # Execute all code blocks\n  cache: true     # Cache results\n  warning: false  # Suppress warnings\n---\n\n## Overview {#sec-overview}\n\nThe numerical integration framework provides **multi-backend**, **multi-method** support for integrating both **deterministic ODEs** and **stochastic SDEs**. The framework consists of **13 core files** organized into a clean 2-track architecture: deterministic and stochastic.\n\n## Architecture Tracks {#sec-architecture-tracks}\n\n```\nTrack 1: Deterministic ODE Integration\n├── IntegratorBase (abstract)\n├── IntegratorFactory (creates integrators)\n├── Backend-Specific Implementations:\n│   ├── ScipyIntegrator (NumPy)\n│   ├── TorchDiffEqIntegrator (PyTorch)\n│   ├── DiffraxIntegrator (JAX)\n│   └── DiffEqPyIntegrator (Julia)\n└── FixedStepIntegrators (RK4, Euler, Midpoint)\n\nTrack 2: Stochastic SDE Integration\n├── SDEIntegratorBase (extends IntegratorBase)\n├── SDEIntegratorFactory (creates SDE integrators)\n├── Backend-Specific Implementations:\n│   ├── TorchSDEIntegrator (PyTorch)\n│   ├── DiffraxSDEIntegrator (JAX)\n│   └── DiffEqPySDEIntegrator (Julia)\n└── CustomBrownianPath (custom noise support)\n```\n\n## File Breakdown {#sec-file-breakdown}\n\n### Track 1: Deterministic ODE Integration {#sec-track-1-deterministic-ode-integration}\n\n#### IntegratorBase {#sec-integratorbase}\n**File:** `integrator_base.py` (512 lines)\n\n**Purpose:** Abstract base class for all numerical integrators\n\n**Key Features:**\n\n- Defines unified interface for all integrators\n- StepMode enum (FIXED vs ADAPTIVE)\n- Performance statistics tracking\n- TypedDict-based IntegrationResult\n\n**Abstract Methods:**\n\n- step(x, u, dt) → x_next                            # Single integration step\n- integrate(x0, u_func, t_span) → IntegrationResult  # Multi-step\n- name: str                                          # Integrator identifier\n\n**Attributes:**\n\n- system: ContinuousSystemBase     # System to integrate\n- dt: float                        # Time step (or initial guess)\n- step_mode: StepMode              # FIXED or ADAPTIVE\n- backend: Backend                 # 'numpy', 'torch', 'jax'\n- rtol, atol: float                # Error tolerances (adaptive)\n- _stats: dict                     # Performance tracking\n\n---\n\n#### IntegratorFactory {#sec-integratorfactory}\n**File:** `integrator_factory.py` (1,267 lines)\n\n**Purpose:** Factory for creating appropriate integrators\n\n**Key Features:**\n\n- Automatic backend/method selection\n- Method-to-backend routing\n- Use case-specific helpers\n- Comprehensive method registry\n\n**Available Backends:**\n\n- **NumPy:** scipy, DiffEqPy (Julia), manual methods\n- **PyTorch:** torchdiffeq\n- **JAX:** diffrax\n\n**Factory Methods:**\n\n\n\n**Method Registry:**\n\n| Method | Backend | Type | Best For |\n|--------|---------|------|----------|\n| LSODA | NumPy (scipy) | Adaptive | General (auto-stiffness) |\n| RK45 | NumPy (scipy) | Adaptive | Non-stiff ODEs |\n| Radau | NumPy (scipy) | Adaptive | Stiff ODEs |\n| BDF | NumPy (scipy) | Adaptive | Very stiff ODEs |\n| Tsit5 | NumPy (Julia) | Adaptive | High performance |\n| Vern9 | NumPy (Julia) | Adaptive | High accuracy |\n| Rodas5 | NumPy (Julia) | Adaptive | Stiff (Rosenbrock) |\n| dopri5 | PyTorch/JAX | Adaptive | Neural ODEs |\n| dopri8 | PyTorch/JAX | Adaptive | High accuracy |\n| tsit5 | JAX (diffrax) | Adaptive | Optimization |\n| euler | Any | Fixed | Educational |\n| rk4 | Any | Fixed | Simple systems |\n\n---\n\n#### ScipyIntegrator {#sec-scipyintegrator}\n**File:** `scipy_integrator.py** (~620 lines estimate)\n\n**Purpose:** Adaptive integration using scipy.integrate.solve_ivp\n\n**Supported Methods:**\n\n- **RK45** (default): Dormand-Prince 5(4) - general purpose\n- **RK23**: Bogacki-Shampine 3(2) - fast, low accuracy\n- **DOP853**: Dormand-Prince 8(5,3) - high accuracy\n- **Radau**: Implicit RK - stiff systems\n- **BDF**: Backward differentiation - very stiff\n- **LSODA**: Auto stiffness detection\n\n**Key Features:**\n\n- Professional-grade adaptive stepping\n- Error control (rtol/atol)\n- Dense output (interpolation)\n- Event detection\n- Both controlled and autonomous systems\n\n**Example:**\n\n::: {#6942e261 .cell execution_count=2}\n``` {.python .cell-code}\nfrom cdesym.systems.base.numerical_integration.scipy_integrator import ScipyIntegrator\nintegrator = ScipyIntegrator(\n    system,\n    method='RK45',\n    rtol=1e-6,\n    atol=1e-8\n)\nresult = integrator.integrate(x0_pendulum_numpy, u_func, t_span=(0, 10))\n```\n:::\n\n\n---\n\n#### TorchDiffEqIntegrator {#sec-torchdiffeqintegrator}\n**File:** `torchdiffeq_integrator.py` (estimated ~800 lines)\n\n**Purpose:** PyTorch integration with GPU acceleration and autograd\n\n**Supported Methods:**\n\n- **dopri5**: Dormand-Prince 5(4)\n- **dopri8**: Dormand-Prince 8\n- **adaptive_heun**: Heun's method\n- **bosh3**: Bogacki-Shampine 3\n- **fehlberg2**: Fehlberg 2(1)\n- **explicit_adams**, **implicit_adams**: Multi-step methods\n\n**Key Features:**\n\n- GPU acceleration\n- Automatic differentiation\n- Adjoint method for memory efficiency\n- Neural ODE support\n\n**Example:**\n\n::: {#3e964a56 .cell execution_count=3}\n``` {.python .cell-code}\nfrom cdesym.systems.base.numerical_integration.torchdiffeq_integrator import TorchDiffEqIntegrator\nintegrator = TorchDiffEqIntegrator(\n    system,\n    method='dopri5',\n    backend='torch',\n    device='cuda:0'\n)\nresult = integrator.integrate(x0_pendulum_torch, u_func, t_span=(0, 10))\n```\n:::\n\n\n---\n\n#### DiffraxIntegrator {#sec-diffraxintegrator}\n**File:** `diffrax_integrator.py` (estimated ~700 lines)\n\n**Purpose:** JAX integration with XLA compilation and autograd\n\n**Supported Methods:**\n\n- **tsit5**: Tsitouras 5(4) - recommended\n- **dopri5**: Dormand-Prince 5(4)\n- **dopri8**: Dormand-Prince 8\n- **heun**: Heun's method\n- **ralston**: Ralston's method\n- **reversible_heun**: Reversible Heun\n\n**Key Features:**\n\n- XLA compilation\n- JAX transformations (jit, vmap, grad)\n- Efficient for optimization\n- Functional programming style\n\n**Example:**\n\n::: {#47265159 .cell execution_count=4}\n``` {.python .cell-code}\nfrom cdesym.systems.base.numerical_integration.diffrax_integrator import DiffraxIntegrator\nintegrator = DiffraxIntegrator(\n    system,\n    method='tsit5',\n    backend='jax'\n)\nresult = integrator.integrate(x0_pendulum_jax, u_func, t_span=(0, 10))\n```\n:::\n\n\n---\n\n#### DiffEqPyIntegrator {#sec-diffeqpyintegrator}\n**File:** `diffeqpy_integrator.py` (estimated ~900 lines)\n\n**Purpose:** Julia's DifferentialEquations.jl via Python bindings\n\n**Supported Methods:**\n\nExtensive Julia solver ecosystem:\n\n- **Explicit RK:** Tsit5, Vern6, Vern7, Vern8, Vern9, DP5, DP8\n- **Rosenbrock:** Rosenbrock23, Rosenbrock32, Rodas4, Rodas5\n- **BDF:** TRBDF2, KenCarp3, KenCarp4, KenCarp5\n- **Radau:** RadauIIA5\n- **Stabilized:** ROCK2, ROCK4\n- **Symplectic:** VelocityVerlet, SymplecticEuler\n- **Auto-switching:** AutoTsit5(Rosenbrock23()), AutoVern7(Rodas5())\n\n**Key Features:**\n\n- Highest performance\n- Automatic stiffness detection\n- Extensive method library\n- Production-grade reliability\n\n**Example:**\n\n::: {#056f50e5 .cell execution_count=5}\n``` {.python .cell-code}\nfrom cdesym.systems.base.numerical_integration.diffeqpy_integrator import DiffEqPyIntegrator\nintegrator = DiffEqPyIntegrator(\n    system,\n    algorithm='Vern9',\n    backend='numpy',\n    reltol=1e-12,\n    abstol=1e-14\n)\nresult = integrator.integrate(x0_pendulum_numpy, u_func, t_span=(0, 10))\n```\n:::\n\n\n---\n\n#### FixedStepIntegrators {#sec-fixedstepintegrators}\n**File:** `fixed_step_integrators.py` (estimated ~600 lines)\n\n**Purpose:** Manual implementation of fixed-step methods\n\n**Supported Methods:**\n\n- **euler**: Forward Euler (order 1)\n- **midpoint**: Midpoint method (order 2)\n- **rk4**: Runge-Kutta 4 (order 4)\n\n**Key Features:**\n\n- Backend-agnostic (NumPy, PyTorch, JAX)\n- Simple, transparent implementations\n- Educational value\n- Constant time step\n\n**Example:**\n\n::: {#4297b3fa .cell execution_count=6}\n``` {.python .cell-code}\nfrom cdesym.systems.base.numerical_integration.fixed_step_integrators import RK4Integrator\nintegrator = RK4Integrator(\n    system,\n    dt=0.01,\n    backend='numpy'\n)\nresult = integrator.integrate(x0_pendulum_numpy, u_func, t_span=(0, 10))\n```\n:::\n\n\n---\n\n### Track 2: Stochastic SDE Integration {#sec-track-2-stochastic-sde-integration}\n\n#### SDEIntegratorBase {#sec-sdeintegratorbase}\n**File:** `sde_integrator_base.py` (1,080 lines)\n\n**Purpose:** Abstract base for SDE integrators\n\n**Mathematical Form:**\n```\ndx = f(x, u, t)dt + g(x, u, t)dW\n```\nwhere:\n\n- f: Drift (deterministic)\n- g: Diffusion (stochastic intensity)\n- dW: Brownian motion increments\n\n**Key Differences from ODE:**\n\n- Random noise generation\n- Weak vs strong convergence\n- Noise structure exploitation\n- Monte Carlo simulation support\n- Itô vs Stratonovich interpretation\n\n**Abstract Methods:**\n\n- step(x, u, dt, dW) → x_next      # Single SDE step with noise\n- integrate(x0, u_func, t_span) → SDEIntegrationResult\n- integrate_monte_carlo(x0, u_func, t_span, n_paths) → SDEIntegrationResult\n\n---\n\n#### SDEIntegratorFactory {#sec-sdeintegratorfactory}\n**File:** `sde_integrator_factory.py` (estimated ~1,000 lines)\n\n**Purpose:** Factory for creating SDE integrators\n\n**Factory Methods:**\n\n::: {#4a4ee654 .cell execute='false' execution_count=7}\n``` {.python .cell-code}\n# create(sde_system, backend, method, dt, **options) → SDEIntegratorBase\n# auto(sde_system, backend=None) → SDEIntegratorBase\n# for_monte_carlo(sde_system, n_paths) → SDEIntegratorBase\n```\n:::\n\n\n**Available Methods:**\n\n| Method | Backend | Convergence | Noise Type |\n|--------|---------|-------------|------------|\n| euler-maruyama | NumPy/PyTorch/JAX | Strong (0.5) | General |\n| milstein | NumPy | Strong (1.0) | Diagonal |\n| heun | PyTorch/JAX | Strong (1.0) | Additive |\n| srk | PyTorch | Strong | General |\n| reversible_heun | PyTorch | Strong | Additive |\n\n---\n\n#### TorchSDEIntegrator {#sec-torchsdeintegrator}\n**File:** `torchsde_integrator.py` (estimated ~800 lines)\n\n**Purpose:** PyTorch SDE integration with torchsde\n\n**Supported Methods:**\n\n- **euler**: Euler-Maruyama (strong order 0.5)\n- **heun**: Heun's method (strong order 1.0 for additive)\n- **srk**: Stochastic Runge-Kutta\n- **reversible_heun**: Reversible Heun (strong order 1.0)\n\n**Key Features:**\n\n- GPU acceleration\n- Adaptive stepping\n- Noise structure exploitation\n- Adjoint method for gradients\n\n**Example:**\n\n::: {#0e26127d .cell execution_count=8}\n``` {.python .cell-code}\nfrom cdesym.systems.base.numerical_integration.stochastic.torchsde_integrator import TorchSDEIntegrator\nintegrator = TorchSDEIntegrator(\n    sde_system,\n    method='adaptive_heun',\n    dt=0.01,\n    backend='torch'\n)\nresult = integrator.integrate(x0_sde_torch, u_func, t_span=(0, 10))\n```\n:::\n\n\n---\n\n#### DiffraxSDEIntegrator {#sec-diffraxsdeintegrator}\n**File:** `diffrax_sde_integrator.py` (estimated ~750 lines)\n\n**Purpose:** JAX SDE integration with diffrax\n\n**Supported Methods:**\n\n- **euler**: Euler-Maruyama\n- **heun**: Heun's method\n- **reversible_heun**: Reversible Heun\n\n**Key Features:**\n\n- JAX transformations\n- XLA compilation\n- Custom noise support\n- Efficient for optimization\n\n**Example:**\n\n::: {#055fe0c1 .cell execution_count=9}\n``` {.python .cell-code}\nfrom cdesym.systems.base.numerical_integration.stochastic.diffrax_sde_integrator import DiffraxSDEIntegrator\nintegrator = DiffraxSDEIntegrator(\n    sde_system,\n    method='euler',\n    dt=0.01,\n    backend='jax',\n    seed=SEED\n)\nresult = integrator.integrate(x0_sde_jax, u_func, t_span=(0, 10))\n```\n:::\n\n\n---\n\n#### DiffEqPySDEIntegrator {#sec-diffeqpysdeintegrator}\n**File:** `diffeqpy_sde_integrator.py` (estimated ~850 lines)\n\n**Purpose:** Julia SDE solvers via DiffEqPy\n\n**Supported Methods:**\n\n- Euler-Maruyama variants\n- Milstein\n- Stochastic Rosenbrock\n- Advanced Julia SDE methods\n\n**Key Features:**\n\n- Production-grade SDE solvers\n- Automatic noise structure detection\n- High-performance algorithms\n\n\n**Example:**\n\n::: {#12822b66 .cell execution_count=10}\n``` {.python .cell-code}\nfrom cdesym.systems.base.numerical_integration.stochastic.diffeqpy_sde_integrator import DiffEqPySDEIntegrator\nintegrator = DiffEqPySDEIntegrator(\n    sde_system,\n    method='EM',\n    dt=0.01,\n    backend='numpy',\n    seed=SEED\n)\nresult = integrator.integrate(x0_sde_numpy, u_func, t_span=(0, 10))\n```\n:::\n\n\n---\n\n#### CustomBrownianPath {#sec-custombrownianpath}\n**File:** `custom_brownian.py` (160 lines)\n\n**Purpose:** Custom Brownian motion for deterministic testing\n\n**Key Features:**\n\n- User-provided noise increments\n- Diffrax AbstractPath interface\n- Deterministic testing support\n- Custom noise patterns\n\n**Example:**\n\n::: {#c4e3fe24 .cell execution_count=11}\n``` {.python .cell-code}\n# Zero noise for testing\nimport jax.numpy as jnp\nfrom jax import random\nkey = random.key(SEED)\n\nfrom cdesym.systems.base.numerical_integration.stochastic.custom_brownian import (\n    CustomBrownianPath, create_custom_or_random_brownian\n)\ndW = jnp.zeros(1)\nbrownian = CustomBrownianPath(0.0, 0.01, dW)\n\n# Or random noise\nbrownian = create_custom_or_random_brownian(\n    key, 0.0, 0.01, shape=(nw,), dW=None\n)\n```\n:::\n\n\n---\n\n## Design Principles {#sec-design-principles}\n\n### 1. Backend Abstraction {#sec-1-backend-abstraction}\n\nAll integrators work across backends:\n\n- **NumPy:** CPU, scipy, Julia integration\n- **PyTorch:** GPU, autograd, neural ODEs\n- **JAX:** XLA, functional, optimization\n\n### 2. Factory Pattern {#sec-2-factory-pattern}\n\nIntegratorFactory and SDEIntegratorFactory provide:\n\n- Automatic method selection\n- Backend-specific routing\n- Convenience constructors\n- Use case optimization\n\n### 3. Unified Result Types {#sec-3-unified-result-types}\n\nAll integrators return TypedDict results:\n\n- **IntegrationResult** for ODEs\n- **SDEIntegrationResult** for SDEs\n- Consistent fields across backends\n- Optional fields for extra diagnostics\n\n### 4. Composition Not Inheritance {#sec-4-composition-not-inheritance}\n\n- Integrators compose with systems\n- No deep inheritance hierarchies\n- Clear separation of concerns\n- Easy to extend\n\n### 5. Performance Tracking {#sec-5-performance-tracking}\nBuilt-in statistics:\n\n::: {#60a0228b .cell evaluate='false' execution_count=12}\n``` {.python .cell-code}\n# integrator._stats = {\n#     'total_fev': int,      # Function evaluations\n#     'total_steps': int,    # Integration steps\n#     'total_time': float,   # Computation time\n# }\n```\n:::\n\n\n## Integration Result Types {#sec-integration-result-types}\n\n### IntegrationResult (ODE) {#sec-integrationresult-ode}\n\n::: {#8f09d405 .cell execute='false' execution_count=13}\n``` {.python .cell-code}\n# {\n#     't': array,              # Time points (T,)\n#     'x': array,              # States (T, nx) - time-major\n#     'success': bool,         # Integration succeeded\n#     'message': str,          # Status message\n#     'nfev': int,             # Function evaluations\n#     'nsteps': int,           # Steps taken\n#     'integration_time': float,  # Wall time (seconds)\n#     'solver': str,           # Integrator name\n    \n#     # Optional (adaptive methods):\n#     'njev': int,             # Jacobian evaluations\n#     'nlu': int,              # LU decompositions\n#     'status': int,           # Solver status code\n#     'sol': object,           # Dense output (if requested)\n#     'dense_output': bool,    # Dense output available\n# }\n```\n:::\n\n\n### SDEIntegrationResult (SDE) {#sec-sdeintegrationresult-sde}\n\n::: {#0ff23f8b .cell execute='false' execution_count=14}\n``` {.python .cell-code}\n# {\n#     # All IntegrationResult fields, plus:\n#     'diffusion_evals': int,     # Diffusion function calls\n#     'noise_samples': array,     # Brownian increments used\n#     'n_paths': int,             # Number of trajectories\n#     'convergence_type': str,    # 'strong' or 'weak'\n#     'sde_type': str,            # 'ito' or 'stratonovich'\n#     'noise_type': str,          # 'additive', 'multiplicative', etc.\n    \n#     # For Monte Carlo (n_paths > 1):\n#     'x': array,                 # (n_paths, T, nx)\n#     'statistics': dict,         # mean, std, quantiles\n# }\n```\n:::\n\n\n## Usage Examples {#sec-usage-examples}\n\n### Example 1: Simple ODE Integration (NumPy) {#sec-example-1-simple-ode-integration-numpy}\n\n::: {#b53af4b9 .cell execution_count=15}\n``` {.python .cell-code}\n# Create integrator automatically\nintegrator = IntegratorFactory.auto(system)\n\n# Integrate\nresult = integrator.integrate(\n    x0=np.array([0.1, 0.0]),\n    u_func=lambda t, x: np.zeros(1),\n    t_span=(0.0, 10.0)\n)\n\nprint(f\"Method: {result['solver']}\")\nprint(f\"Steps: {result['nsteps']}\")\nprint(f\"Success: {result['success']}\")\n```\n:::\n\n\n### Example 2: High-Accuracy Julia Integration {#sec-example-3-high-accuracy-julia-integration}\n\n::: {#5436e463 .cell execution_count=16}\n``` {.python .cell-code}\nfrom cdesym import ContinuousSymbolicSystem, IntegratorFactory\n\n# Create Julia integrator with high accuracy\nintegrator = IntegratorFactory.for_julia(\n    system,\n    algorithm='Vern9',  # 9th order\n    reltol=1e-12,\n    abstol=1e-14\n)\n\nresult = integrator.integrate(x0_pendulum_numpy, u_func, t_span=(0, 100))\nprint(f\"Accurate to {result['nfev']} function evaluations\")\n```\n:::\n\n\n### Example 3: Stochastic SDE Integration {#sec-example-4-stochastic-sde-integration}\n\n::: {#a427f83c .cell execution_count=17}\n``` {.python .cell-code}\n# Create SDE integrator\nintegrator = SDEIntegratorFactory.create(\n    sde_system,\n    backend='torch',\n    method='adaptive_heun',\n    dt=0.01,\n    seed=SEED\n)\n\n# Single trajectory\nresult = integrator.integrate(x0_sde_torch, u_func, t_span=(0, 10))\n# Integrators do not return noise type, only sde_system.integrate() would\n# print(f\"Noise type: {result['noise_type']}\")\nprint(f\"SDE type: {result['sde_type']}\")\n\n# typical UI (also demonstrating temporary backend switching)\nwith sde_system.use_backend('torch'):\n    result = sde_system.integrate(\n        x0=x0_sde_torch,\n        method='adaptive_heun',\n        dt=0.01,\n        seed=SEED\n    )\n\nprint(f\"Noise type: {result['noise_type']}\")\nprint(f\"SDE type: {result['sde_type']}\")\n```\n:::\n\n\n### Example 4: Monte Carlo SDE Simulation {#sec-example-5-monte-carlo-sde-simulation}\n\n::: {#ec6483b4 .cell execution_count=18}\n``` {.python .cell-code}\n# Multiple trajectories for uncertainty quantification\nresult = integrator.integrate_monte_carlo(\n    x0=np.array([1.0]),\n    u_func=lambda t, x: np.zeros(1),\n    t_span=(0, 10),\n    n_paths=1000\n)\n\n# Get statistics\n\nfrom cdesym.systems.base.numerical_integration.stochastic import get_trajectory_statistics\nstats = get_trajectory_statistics(result)\n\nprint(f\"Mean at t=10: {stats['mean'][-1]}\")\nprint(f\"Std at t=10: {stats['std'][-1]}\")\nprint(f\"95% CI: [{stats['q25'][-1]}, {stats['q75'][-1]}]\")\n```\n:::\n\n\n### Example 5: Custom Noise (Deterministic Testing) {#sec-example-6-custom-noise-deterministic-testing}\n\n::: {#37499b2a .cell execution_count=19}\n``` {.python .cell-code}\nimport jax.numpy as jnp\nfrom cdesym.systems.base.numerical_integration.stochastic.custom_brownian import (\n    CustomBrownianPath\n)\n\n# Zero noise for deterministic testing\n# NOTE: For integrate(), provide ONE dW that spans the ENTIRE integration\n# This is different from step() which uses per-step dW\ndW = jnp.zeros((nw,))\nbrownian = CustomBrownianPath(0.0, 1.0, dW)  # t0=0, t1=1 matching t_span\n\n# need an integrator in JAX for this\nintegrator = SDEIntegratorFactory.create(\n    sde_system,\n    backend='jax',\n    method='Heun',  # Use 'Euler' not 'Heun' (check available methods)\n    dt=0.01,\n    seed=SEED\n)\n\n# Use in integration with custom Brownian path\nresult = integrator.integrate(\n    x0_sde_jax, \n    u_func, \n    t_span=(0, 1),\n    brownian_path=brownian  # Pass the custom path\n)\n```\n:::\n\n\n**Important notes for custom Brownian paths:**\n\n1. **Time span matching**: The `CustomBrownianPath(t0, t1, dW)` should have `t0` and `t1` matching your integration `t_span`\n2. **Single dW for entire integration**: Unlike `step()` where you provide per-step `dW`, for `integrate()` you provide ONE `dW` representing the entire interval\n3. **Diffrax handles interpolation**: Diffrax will internally query the Brownian path at different times using the `evaluate()` method\n\n## Integrator Selection Guide {#sec-integrator-selection-guide}\n\n### By Use Case {#sec-by-use-case}\n\n| Use Case | Recommended Integrator | Reason |\n|----------|----------------------|---------|\n| General ODE | `IntegratorFactory.for_production(system)` | LSODA auto-stiffness |\n| Neural ODE | `IntegratorFactory.for_neural_ode(system)` | TorchDiffEq adjoint |\n| Optimization | `IntegratorFactory.for_optimization(system)` | Diffrax JAX |\n| High Accuracy | `IntegratorFactory.for_julia(system, 'Vern9')` | Julia 9th order |\n| Stiff ODE | `ScipyIntegrator(system, method='BDF')` | Implicit BDF |\n| Simple ODE | `RK4Integrator(system, dt=0.01)` | Classic RK4 |\n| SDE (general) | `SDEIntegratorFactory.auto(sde_system)` | Best for noise type |\n| Monte Carlo | `SDEIntegratorFactory.for_monte_carlo(...)` | Parallelized |\n\n### By Backend {#sec-by-backend}\n\n| Backend | ODE Integrator | SDE Integrator |\n|---------|---------------|----------------|\n| NumPy | ScipyIntegrator, DiffEqPyIntegrator | (limited support) |\n| PyTorch | TorchDiffEqIntegrator | TorchSDEIntegrator |\n| JAX | DiffraxIntegrator | DiffraxSDEIntegrator |\n\n### By System Properties {#sec-by-system-properties}\n\n| System Type | Best Integrator |\n|-------------|-----------------|\n| Non-stiff | RK45, Tsit5, dopri5 |\n| Stiff | BDF, Radau, Rodas5 |\n| High accuracy | Vern9, DOP853 |\n| Real-time | RK4, euler (fixed-step) |\n| Additive noise SDE | Heun (strong order 1.0) |\n| General SDE | Euler-Maruyama |\n\n## Key Strengths {#sec-key-strengths}\n\n1. **Multi-Backend Support** - Seamless NumPy/PyTorch/JAX switching\n2. **Extensive Method Library** - 40+ integration methods\n3. **Factory Pattern** - Automatic method selection\n4. **Type Safety** - TypedDict results with IDE support\n5. **Performance** - GPU acceleration, XLA compilation, Julia performance\n6. **Flexibility** - Fixed and adaptive stepping\n7. **Stochastic Support** - Full SDE integration framework\n8. **Noise Structure** - Exploits additive/diagonal/scalar noise\n9. **Monte Carlo** - Built-in multi-trajectory simulation\n10. **Testing** - Custom noise for deterministic testing\n\nThis framework enables state-of-the-art numerical integration for control theory and machine learning applications!\n\n",
    "supporting": [
      "Integration_Framework_Architecture_files"
    ],
    "filters": [],
    "includes": {}
  }
}